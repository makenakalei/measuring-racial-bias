{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(701, 9)"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# df1 = pd.read_csv('test400_outputs.csv')\n",
    "# df2 = pd.read_csv('test59_outputs.csv')\n",
    "# df = pd.concat([df1, df2], ignore_index=True)\n",
    "df = pd.read_csv('test705_outputs.csv')\n",
    "df.head()\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['White', 'East Asian', 'Latino_Hispanic', 'Middle Eastern',\n",
       "       'Black', 'Southeast Asian'], dtype=object)"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['race'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['White', 'Asian', 'Black', 'Indian'], dtype=object)"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['race4'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>face_name_align</th>\n",
       "      <th>race</th>\n",
       "      <th>race4</th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>race_scores_fair</th>\n",
       "      <th>race_scores_fair_4</th>\n",
       "      <th>gender_scores_fair</th>\n",
       "      <th>age_scores_fair</th>\n",
       "      <th>race_ind</th>\n",
       "      <th>race4_ind</th>\n",
       "      <th>ethnicity_comp</th>\n",
       "      <th>img_name_clean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>detected_faces/20170103200335831_face0.jpg</td>\n",
       "      <td>White</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>10-19</td>\n",
       "      <td>[8.2806402e-01 1.8271449e-04 3.3872772e-02 3.0...</td>\n",
       "      <td>[0.9676284  0.00491149 0.02388687 0.00357327]</td>\n",
       "      <td>[0.44621623 0.55378383]</td>\n",
       "      <td>[4.5707508e-05 1.3924231e-01 8.3207673e-01 2.1...</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>20170103200335831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>detected_faces/20170103212955884_face0.jpg</td>\n",
       "      <td>White</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>10-19</td>\n",
       "      <td>[9.1871512e-01 3.8506234e-05 2.8681878e-02 6.2...</td>\n",
       "      <td>[0.9813499  0.00196068 0.0152862  0.00140321]</td>\n",
       "      <td>[0.01931252 0.98068744]</td>\n",
       "      <td>[1.0350227e-04 1.5916879e-01 6.5006316e-01 1.7...</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>20170103212955884</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>detected_faces/20170103210552842_face0.jpg</td>\n",
       "      <td>East Asian</td>\n",
       "      <td>Asian</td>\n",
       "      <td>Male</td>\n",
       "      <td>3-9</td>\n",
       "      <td>[0.00697174 0.00104053 0.00953167 0.8601581  0...</td>\n",
       "      <td>[1.6544726e-02 2.0209912e-03 9.8095042e-01 4.8...</td>\n",
       "      <td>[0.6687252  0.33127484]</td>\n",
       "      <td>[1.3211207e-01 7.7539891e-01 5.7414137e-02 1.9...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>20170103210552842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>detected_faces/20170103182720889_face0.jpg</td>\n",
       "      <td>White</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>30-39</td>\n",
       "      <td>[9.9959368e-01 1.0242115e-06 9.0160669e-05 1.1...</td>\n",
       "      <td>[9.9845886e-01 7.6688171e-05 1.2414175e-04 1.3...</td>\n",
       "      <td>[0.00156806 0.998432  ]</td>\n",
       "      <td>[9.8462885e-07 5.7339337e-05 9.3195215e-03 4.0...</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>20170103182720889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>detected_faces/20170103183939755_face0.jpg</td>\n",
       "      <td>White</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>40-49</td>\n",
       "      <td>[9.8262525e-01 7.7606161e-04 1.0399933e-03 1.0...</td>\n",
       "      <td>[9.8820978e-01 6.2866093e-05 1.1613224e-02 1.1...</td>\n",
       "      <td>[0.27687255 0.7231275 ]</td>\n",
       "      <td>[1.32519301e-04 7.57471716e-04 5.70024457e-03 ...</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>20170103183939755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>detected_faces/20170103201305015_face0.jpg</td>\n",
       "      <td>Latino_Hispanic</td>\n",
       "      <td>Black</td>\n",
       "      <td>Male</td>\n",
       "      <td>10-19</td>\n",
       "      <td>[0.09850515 0.09524991 0.7516521  0.002715   0...</td>\n",
       "      <td>[0.17779705 0.56735325 0.06371013 0.19113955]</td>\n",
       "      <td>[0.99261427 0.00738568]</td>\n",
       "      <td>[1.2022854e-05 1.1534345e-02 7.1233946e-01 2.6...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>20170103201305015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>detected_faces/20170103224732417_face0.jpg</td>\n",
       "      <td>White</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>30-39</td>\n",
       "      <td>[8.8875389e-01 8.9304609e-04 6.3222706e-02 4.0...</td>\n",
       "      <td>[0.9739755  0.00421668 0.00461154 0.01719627]</td>\n",
       "      <td>[0.11265264 0.88734734]</td>\n",
       "      <td>[7.75363560e-07 3.83184888e-05 1.30977435e-02 ...</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>20170103224732417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>detected_faces/20170103200427437_face0.jpg</td>\n",
       "      <td>Latino_Hispanic</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>3-9</td>\n",
       "      <td>[0.22234572 0.011612   0.6767265  0.01512295 0...</td>\n",
       "      <td>[0.59569204 0.12783305 0.22002542 0.05644951]</td>\n",
       "      <td>[0.8292572  0.17074278]</td>\n",
       "      <td>[3.5696137e-03 8.6889255e-01 1.2425893e-01 2.3...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>20170103200427437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>detected_faces/20170103223351703_face0.jpg</td>\n",
       "      <td>Latino_Hispanic</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>20-29</td>\n",
       "      <td>[0.4064687  0.00864318 0.52038884 0.00167283 0...</td>\n",
       "      <td>[0.6439037  0.20800854 0.00401308 0.14407463]</td>\n",
       "      <td>[0.00197943 0.9980206 ]</td>\n",
       "      <td>[4.0133713e-07 1.7152191e-03 2.6408464e-01 6.8...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>20170103223351703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>detected_faces/20170103223013127_face0.jpg</td>\n",
       "      <td>Black</td>\n",
       "      <td>Black</td>\n",
       "      <td>Female</td>\n",
       "      <td>20-29</td>\n",
       "      <td>[3.0338898e-04 9.9260837e-01 4.4696666e-03 8.7...</td>\n",
       "      <td>[2.7115870e-04 9.6844447e-01 3.0154651e-02 1.1...</td>\n",
       "      <td>[0.00144985 0.9985501 ]</td>\n",
       "      <td>[5.0299941e-06 2.3427799e-03 1.0839571e-01 6.8...</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>20170103223013127</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>70 rows Ã— 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                               face_name_align             race  race4  \\\n",
       "0   detected_faces/20170103200335831_face0.jpg            White  White   \n",
       "1   detected_faces/20170103212955884_face0.jpg            White  White   \n",
       "2   detected_faces/20170103210552842_face0.jpg       East Asian  Asian   \n",
       "3   detected_faces/20170103182720889_face0.jpg            White  White   \n",
       "4   detected_faces/20170103183939755_face0.jpg            White  White   \n",
       "..                                         ...              ...    ...   \n",
       "65  detected_faces/20170103201305015_face0.jpg  Latino_Hispanic  Black   \n",
       "66  detected_faces/20170103224732417_face0.jpg            White  White   \n",
       "67  detected_faces/20170103200427437_face0.jpg  Latino_Hispanic  White   \n",
       "68  detected_faces/20170103223351703_face0.jpg  Latino_Hispanic  White   \n",
       "69  detected_faces/20170103223013127_face0.jpg            Black  Black   \n",
       "\n",
       "    gender    age                                   race_scores_fair  \\\n",
       "0   Female  10-19  [8.2806402e-01 1.8271449e-04 3.3872772e-02 3.0...   \n",
       "1   Female  10-19  [9.1871512e-01 3.8506234e-05 2.8681878e-02 6.2...   \n",
       "2     Male    3-9  [0.00697174 0.00104053 0.00953167 0.8601581  0...   \n",
       "3   Female  30-39  [9.9959368e-01 1.0242115e-06 9.0160669e-05 1.1...   \n",
       "4   Female  40-49  [9.8262525e-01 7.7606161e-04 1.0399933e-03 1.0...   \n",
       "..     ...    ...                                                ...   \n",
       "65    Male  10-19  [0.09850515 0.09524991 0.7516521  0.002715   0...   \n",
       "66  Female  30-39  [8.8875389e-01 8.9304609e-04 6.3222706e-02 4.0...   \n",
       "67    Male    3-9  [0.22234572 0.011612   0.6767265  0.01512295 0...   \n",
       "68  Female  20-29  [0.4064687  0.00864318 0.52038884 0.00167283 0...   \n",
       "69  Female  20-29  [3.0338898e-04 9.9260837e-01 4.4696666e-03 8.7...   \n",
       "\n",
       "                                   race_scores_fair_4  \\\n",
       "0       [0.9676284  0.00491149 0.02388687 0.00357327]   \n",
       "1       [0.9813499  0.00196068 0.0152862  0.00140321]   \n",
       "2   [1.6544726e-02 2.0209912e-03 9.8095042e-01 4.8...   \n",
       "3   [9.9845886e-01 7.6688171e-05 1.2414175e-04 1.3...   \n",
       "4   [9.8820978e-01 6.2866093e-05 1.1613224e-02 1.1...   \n",
       "..                                                ...   \n",
       "65      [0.17779705 0.56735325 0.06371013 0.19113955]   \n",
       "66      [0.9739755  0.00421668 0.00461154 0.01719627]   \n",
       "67      [0.59569204 0.12783305 0.22002542 0.05644951]   \n",
       "68      [0.6439037  0.20800854 0.00401308 0.14407463]   \n",
       "69  [2.7115870e-04 9.6844447e-01 3.0154651e-02 1.1...   \n",
       "\n",
       "         gender_scores_fair  \\\n",
       "0   [0.44621623 0.55378383]   \n",
       "1   [0.01931252 0.98068744]   \n",
       "2   [0.6687252  0.33127484]   \n",
       "3   [0.00156806 0.998432  ]   \n",
       "4   [0.27687255 0.7231275 ]   \n",
       "..                      ...   \n",
       "65  [0.99261427 0.00738568]   \n",
       "66  [0.11265264 0.88734734]   \n",
       "67  [0.8292572  0.17074278]   \n",
       "68  [0.00197943 0.9980206 ]   \n",
       "69  [0.00144985 0.9985501 ]   \n",
       "\n",
       "                                      age_scores_fair  race_ind  race4_ind  \\\n",
       "0   [4.5707508e-05 1.3924231e-01 8.3207673e-01 2.1...         3          2   \n",
       "1   [1.0350227e-04 1.5916879e-01 6.5006316e-01 1.7...         3          2   \n",
       "2   [1.3211207e-01 7.7539891e-01 5.7414137e-02 1.9...         0          0   \n",
       "3   [9.8462885e-07 5.7339337e-05 9.3195215e-03 4.0...         3          2   \n",
       "4   [1.32519301e-04 7.57471716e-04 5.70024457e-03 ...         3          2   \n",
       "..                                                ...       ...        ...   \n",
       "65  [1.2022854e-05 1.1534345e-02 7.1233946e-01 2.6...         1          1   \n",
       "66  [7.75363560e-07 3.83184888e-05 1.30977435e-02 ...         3          2   \n",
       "67  [3.5696137e-03 8.6889255e-01 1.2425893e-01 2.3...         1          2   \n",
       "68  [4.0133713e-07 1.7152191e-03 2.6408464e-01 6.8...         1          2   \n",
       "69  [5.0299941e-06 2.3427799e-03 1.0839571e-01 6.8...         4          1   \n",
       "\n",
       "    ethnicity_comp     img_name_clean  \n",
       "0                3  20170103200335831  \n",
       "1                3  20170103212955884  \n",
       "2                0  20170103210552842  \n",
       "3                3  20170103182720889  \n",
       "4                3  20170103183939755  \n",
       "..             ...                ...  \n",
       "65               5  20170103201305015  \n",
       "66               3  20170103224732417  \n",
       "67               5  20170103200427437  \n",
       "68               5  20170103223351703  \n",
       "69               4  20170103223013127  \n",
       "\n",
       "[70 rows x 13 columns]"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mapping1 = {'East Asian': 0, 'Latino_Hispanic': 1, 'Southeast Asian': 2, 'White': 3,\n",
    "       'Black': 4, 'Middle Eastern': 5}\n",
    "df['race_ind'] = df['race'].map(mapping1)\n",
    "\n",
    "mapping2 = {'Asian': 0, 'Black': 1, 'White': 2, 'Indian': 3}\n",
    "df['race4_ind'] = df['race4'].map(mapping2)\n",
    "\n",
    "mappingComp = {0: 0, 1: 5, 2: 2, 3: 3, 4: 4, 5: 5} #to get accuracy, maps Middle Eastern and Latino_Hispanic to same id\n",
    "df['ethnicity_comp'] = df['race_ind'].map(mappingComp)\n",
    "\n",
    "clean_filename = lambda x: x.replace(\"detected_faces/\", \"\").replace(\"_face0.jpg\", \"\")\n",
    "df['img_name_clean'] = df['face_name_align'].apply(clean_filename)\n",
    "df.head(70)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>ethnicity</th>\n",
       "      <th>gender</th>\n",
       "      <th>img_name</th>\n",
       "      <th>pixels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>20161219203650636.jpg.chip.jpg</td>\n",
       "      <td>129 128 128 126 127 130 133 135 139 142 145 14...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>20161219222752047.jpg.chip.jpg</td>\n",
       "      <td>164 74 111 168 169 171 175 182 184 188 193 199...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>20161219222832191.jpg.chip.jpg</td>\n",
       "      <td>67 70 71 70 69 67 70 79 90 103 116 132 145 155...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>20161220144911423.jpg.chip.jpg</td>\n",
       "      <td>193 197 198 200 199 200 202 203 204 205 208 21...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>20161220144914327.jpg.chip.jpg</td>\n",
       "      <td>202 205 209 210 209 209 210 211 212 214 218 21...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age  ethnicity  gender                        img_name  \\\n",
       "0    1          2       0  20161219203650636.jpg.chip.jpg   \n",
       "1    1          2       0  20161219222752047.jpg.chip.jpg   \n",
       "2    1          2       0  20161219222832191.jpg.chip.jpg   \n",
       "3    1          2       0  20161220144911423.jpg.chip.jpg   \n",
       "4    1          2       0  20161220144914327.jpg.chip.jpg   \n",
       "\n",
       "                                              pixels  \n",
       "0  129 128 128 126 127 130 133 135 139 142 145 14...  \n",
       "1  164 74 111 168 169 171 175 182 184 188 193 199...  \n",
       "2  67 70 71 70 69 67 70 79 90 103 116 132 145 155...  \n",
       "3  193 197 198 200 199 200 202 203 204 205 208 21...  \n",
       "4  202 205 209 210 209 209 210 211 212 214 218 21...  "
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#dataset: https://www.kaggle.com/datasets/nipunarora8/age-gender-and-ethnicity-face-data-csv\n",
    "#0 to 4, denoting White, Black, Asian, Indian, and Others (like Hispanic, Latino, Middle Eastern)\n",
    "\n",
    "trueY_df = pd.read_csv('/Users/makenarobison/Desktop/Computer Vision Research/age_gender.csv')\n",
    "\n",
    "trueY_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(23705, 7)"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ethinicity key: 0 to 4, denoting White, Black, Asian, Indian, and Others (like Hispanic, Latino, Middle Eastern)\n",
    "\n",
    "mapping3 = {0: 3, 1: 4, 2: 0, 3: 2, 4: 5}\n",
    "trueY_df['ethnicity_comp_true'] = trueY_df['ethnicity'].map(mapping3)\n",
    "\n",
    "clean_filename = lambda x: x.replace(\".jpg.chip.jpg\", \"\")\n",
    "trueY_df['img_name_clean'] = trueY_df['img_name'].apply(clean_filename)\n",
    "\n",
    "trueY_df.head()\n",
    "\n",
    "trueY_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(701, 13)\n",
      "(23705, 7)\n",
      "(701, 19)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(701, 3)"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#accuracy comparison\n",
    "print(df.shape)\n",
    "print(trueY_df.shape)\n",
    "merged_df = pd.merge(df, trueY_df, on='img_name_clean')\n",
    "print(merged_df.shape)\n",
    "# Filter matching IDs\n",
    "matching_ids_df = merged_df[merged_df['img_name_clean'].notna()]\n",
    "\n",
    "selected_columns = ['ethnicity', 'ethnicity_comp_true', 'ethnicity_comp']\n",
    "selected_df = matching_ids_df[selected_columns]\n",
    "\n",
    "selected_df.head(30)\n",
    "selected_df.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 21, 2: 0, 3: 290, 4: 17, 5: 90}\n",
      "{0: 36, 2: 1, 3: 311, 4: 25, 5: 328}\n",
      "{0: 15, 2: 1, 3: 21, 4: 8, 5: 238}\n",
      "Class 0:\n",
      "  Accuracy: 0.58\n",
      "  Error Rate: 0.42\n",
      "  Precision: 0.58\n",
      "Class 2:\n",
      "  Accuracy: 0.00\n",
      "  Error Rate: 1.00\n",
      "  Precision: 0.00\n",
      "Class 3:\n",
      "  Accuracy: 0.93\n",
      "  Error Rate: 0.07\n",
      "  Precision: 0.93\n",
      "Class 4:\n",
      "  Accuracy: 0.68\n",
      "  Error Rate: 0.32\n",
      "  Precision: 0.68\n",
      "Class 5:\n",
      "  Accuracy: 0.27\n",
      "  Error Rate: 0.73\n",
      "  Precision: 0.27\n"
     ]
    }
   ],
   "source": [
    "true_pred = {0: 0, 2: 0, 3: 0, 4: 0, 5: 0}\n",
    "error_pred = {0: 0, 2: 0, 3: 0, 4: 0, 5: 0}\n",
    "total_pred = {0: 0, 2: 0, 3: 0, 4: 0, 5: 0}\n",
    "error_imgs = []\n",
    "# Compare columns for matched IDs\n",
    "for index, row in matching_ids_df.iterrows():\n",
    "    id_val = row['img_name_clean']\n",
    "    pred_val = row['ethnicity_comp']\n",
    "    actual_val = row['ethnicity_comp_true']\n",
    "    \n",
    "    total_pred[actual_val] += 1\n",
    "    # Example comparison logic\n",
    "    if pred_val == actual_val:\n",
    "        true_pred[actual_val] += 1\n",
    "    else:\n",
    "        error_imgs.append(id_val)\n",
    "        error_pred[actual_val] += 1\n",
    "\n",
    "accuracy = sum(true_pred.values()) / sum(total_pred.values())\n",
    "\n",
    "error = sum(error_pred.values()) / sum(total_pred.values())\n",
    "\n",
    "#precision = true_pred[1] / (true_pred[1] + error_pred[1])\n",
    "\n",
    "# Calculate accuracy, error rate, and precision for each class\n",
    "class_accuracy = {}\n",
    "class_error_rate = {}\n",
    "class_precision = {}\n",
    "\n",
    "for class_val in true_pred.keys():\n",
    " if class_val != 1 and total_pred[class_val] > 0: \n",
    "        class_accuracy[class_val] = true_pred[class_val] / total_pred[class_val]\n",
    "        class_error_rate[class_val] = error_pred[class_val] / total_pred[class_val]\n",
    "        if true_pred[class_val] + error_pred[class_val] > 0:\n",
    "            class_precision[class_val] = true_pred[class_val] / (true_pred[class_val] + error_pred[class_val])\n",
    "        else:\n",
    "            class_precision[class_val] = None\n",
    "\n",
    "# Display metrics for each class\n",
    "print(true_pred)\n",
    "print(total_pred)\n",
    "print(error_pred)\n",
    "for class_val in true_pred.keys():\n",
    "   if class_val != 1 and total_pred[class_val] > 0:  # Skip class 1 and check if there are instances of this class\n",
    "        print(f\"Class {class_val}:\")\n",
    "        print(f\"  Accuracy: {class_accuracy[class_val]:.2f}\")\n",
    "        print(f\"  Error Rate: {class_error_rate[class_val]:.2f}\")\n",
    "        if class_precision[class_val] is not None:\n",
    "            print(f\"  Precision: {class_precision[class_val]:.2f}\")\n",
    "        else:\n",
    "            print(\"  Precision: Not calculable (no instances)\")\n",
    "            "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "thesis-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
